{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fire\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim.swa_utils as swa_utils\n",
    "import torchcde\n",
    "import torchsde\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipSwish(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.909 * torch.nn.functional.silu(x)\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_size, out_size, mlp_size, num_layers, tanh):\n",
    "        super().__init__()\n",
    "\n",
    "        model = [torch.nn.Linear(in_size, mlp_size),\n",
    "                 LipSwish()]\n",
    "        for _ in range(num_layers - 1):\n",
    "            model.append(torch.nn.Linear(mlp_size, mlp_size))\n",
    "            ###################\n",
    "            # LipSwish activations are useful to constrain the Lipschitz constant of the discriminator.\n",
    "            # (For simplicity we additionally use them in the generator, but that's less important.)\n",
    "            ###################\n",
    "            model.append(LipSwish())\n",
    "        model.append(torch.nn.Linear(mlp_size, out_size))\n",
    "        if tanh:\n",
    "            model.append(torch.nn.Tanh())\n",
    "        self._model = torch.nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "    \n",
    "class OUGeneratorFunc(torch.nn.Module):\n",
    "    sde_type = \"stratonovich\"\n",
    "    noise_type = \"general\"\n",
    "    def __init__(self, noise_size, hidden_size, mlp_size, num_layers, mu=0.02, theta=0.1):\n",
    "        super().__init__()\n",
    "        self._noise_size = noise_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self._output_size = 1\n",
    "        self._mu = mu\n",
    "        self._theta = theta\n",
    "        self._linear = torch.nn.Linear(hidden_size,  self._output_size)  # Maps MLP to be 1 dimensional\n",
    "\n",
    "        self._drift_mlp = MLP(\n",
    "            1 + 1, hidden_size, mlp_size, num_layers, tanh=True\n",
    "        )  # Drift MLP for price\n",
    "        self._vol_mlp = MLP(\n",
    "            1 + 1, hidden_size, mlp_size, num_layers, tanh=True\n",
    "        )  # MLP for volatility of volatility\n",
    "\n",
    "    def f_and_g(self, t, x):\n",
    "        # x consists of [S_t, v_t]\n",
    "        t_expanded = t.expand(x.size(0), 1)\n",
    "        tx = torch.cat([t_expanded, x], dim=1)  # (t, S_t)\n",
    "\n",
    "        # Drift components\n",
    "        drift = self._mu * t_expanded - self._theta * x \n",
    "\n",
    "        # Diffusion components\n",
    "        diffusion = self._vol_mlp(tx)\n",
    "        diffusion = self._linear(diffusion) \n",
    "\n",
    "        return drift, diffusion.view(x.size(0), self._output_size, self._noise_size)\n",
    "\n",
    "O = OUGeneratorFunc(noise_size=1, hidden_size=16, mlp_size=16, num_layers=1)\n",
    "batch_size = 100\n",
    "time = torch.randn(1, 1)\n",
    "x = torch.tensor(batch_size * [[10]])\n",
    "mu, sigma = O.f_and_g(time, x)\n",
    "assert [x for x in mu.shape] == [100, 1]\n",
    "assert [x for x in sigma.shape] == [100, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, data_size, initial_noise_size, noise_size, hidden_size, mlp_size, num_layers):\n",
    "        super().__init__()\n",
    "        self._initial_noise_size = initial_noise_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self.data_size = 1\n",
    "        self._initial = MLP(initial_noise_size, hidden_size, mlp_size, num_layers, tanh=False)\n",
    "        self._func = OUGeneratorFunc(noise_size, hidden_size, mlp_size, num_layers)\n",
    "\n",
    "    def forward(self, ts, batch_size):\n",
    "        # ts has shape (t_size,) and corresponds to the points we want to evaluate the SDE at.\n",
    "\n",
    "        ###################\n",
    "        # Actually solve the SDE.\n",
    "        ###################\n",
    "        init_noise = torch.randn(batch_size, self._initial_noise_size, device=ts.device)\n",
    "        x0 = self._initial(init_noise)\n",
    "\n",
    "        ###################\n",
    "        # We use the reversible Heun method to get accurate gradients whilst using the adjoint method.\n",
    "        ###################\n",
    "        xs = torchsde.sdeint_adjoint(self._func, x0, ts, method='reversible_heun', dt=1.0,\n",
    "                                     adjoint_method='adjoint_reversible_heun',)\n",
    "        ys = xs.transpose(0, 1)\n",
    "\n",
    "        ###################\n",
    "        # Normalise the data to the form that the discriminator expects, in particular including time as a channel.\n",
    "        ###################\n",
    "        ts = ts.unsqueeze(0).unsqueeze(-1).expand(batch_size, ts.size(0), 1)\n",
    "        return torchcde.linear_interpolation_coeffs(torch.cat([ts, ys], dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorFunc(torch.nn.Module):\n",
    "    def __init__(self, data_size, hidden_size, mlp_size, num_layers):\n",
    "        super().__init__()\n",
    "        self._data_size = data_size\n",
    "        self._hidden_size = hidden_size\n",
    "\n",
    "        # tanh is important for model performance\n",
    "        self._module = MLP(1 + hidden_size, hidden_size * (1 + data_size), mlp_size, num_layers, tanh=True)\n",
    "\n",
    "    def forward(self, t, h):\n",
    "        # t has shape ()\n",
    "        # h has shape (batch_size, hidden_size)\n",
    "        t = t.expand(h.size(0), 1)\n",
    "        th = torch.cat([t, h], dim=1)\n",
    "        return self._module(th).view(h.size(0), self._hidden_size, 1 + self._data_size)\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, data_size, hidden_size, mlp_size, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self._initial = MLP(1 + data_size, hidden_size, mlp_size, num_layers, tanh=False)\n",
    "        self._func = DiscriminatorFunc(data_size, hidden_size, mlp_size, num_layers)\n",
    "        self._readout = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, ys_coeffs):\n",
    "        # ys_coeffs has shape (batch_size, t_size, 1 + data_size)\n",
    "        # The +1 corresponds to time. When solving CDEs, It turns out to be most natural to treat time as just another\n",
    "        # channel: in particular this makes handling irregular data quite easy, when the times may be different between\n",
    "        # different samples in the batch.\n",
    "\n",
    "        Y = torchcde.LinearInterpolation(ys_coeffs)\n",
    "        Y0 = Y.evaluate(Y.interval[0])\n",
    "        h0 = self._initial(Y0)\n",
    "        hs = torchcde.cdeint(Y, self._func, h0, Y.interval, method='reversible_heun', backend='torchsde', dt=1.0,\n",
    "                             adjoint_method='adjoint_reversible_heun',\n",
    "                             adjoint_params=(ys_coeffs,) + tuple(self._func.parameters()))\n",
    "        score = self._readout(hs[:, -1])\n",
    "        return score.mean()\n",
    "\n",
    "\n",
    "###################\n",
    "# Generate some data. For this example we generate some synthetic data from a time-dependent Ornstein-Uhlenbeck SDE.\n",
    "###################\n",
    "def get_data(batch_size, device):\n",
    "    dataset_size = 1000\n",
    "    t_size = 64\n",
    "\n",
    "    class OrnsteinUhlenbeckSDE(torch.nn.Module):\n",
    "        sde_type = 'ito'\n",
    "        noise_type = 'scalar'\n",
    "\n",
    "        def __init__(self, mu, theta, sigma):\n",
    "            super().__init__()\n",
    "            self.register_buffer('mu', torch.as_tensor(mu))\n",
    "            self.register_buffer('theta', torch.as_tensor(theta))\n",
    "            self.register_buffer('sigma', torch.as_tensor(sigma))\n",
    "\n",
    "        def f(self, t, y):\n",
    "            return self.mu * t - self.theta * y\n",
    "\n",
    "        def g(self, t, y):\n",
    "            return self.sigma.expand(y.size(0), 1, 1) * (2 * t / t_size)\n",
    "\n",
    "    ou_sde = OrnsteinUhlenbeckSDE(mu=0.02, theta=0.1, sigma=0.4).to(device)\n",
    "    y0 = torch.rand(dataset_size, device=device).unsqueeze(-1) * 2 - 1\n",
    "    ts = torch.linspace(0, t_size - 1, t_size, device=device)\n",
    "    ys = torchsde.sdeint(ou_sde, y0, ts, dt=1e-1)\n",
    "\n",
    "    ###################\n",
    "    # To demonstrate how to handle irregular data, then here we additionally drop some of the data (by setting it to\n",
    "    # NaN.)\n",
    "    ###################\n",
    "    ys_num = ys.numel()\n",
    "    to_drop = torch.randperm(ys_num)[:int(0.3 * ys_num)]\n",
    "    ys.view(-1)[to_drop] = float('nan')\n",
    "\n",
    "    ###################\n",
    "    # Typically important to normalise data. Note that the data is normalised with respect to the statistics of the\n",
    "    # initial data, _not_ the whole time series. This seems to help the learning process, presumably because if the\n",
    "    # initial condition is wrong then it's pretty hard to learn the rest of the SDE correctly.\n",
    "    ###################\n",
    "    y0_flat = ys[0].view(-1)\n",
    "    y0_not_nan = y0_flat.masked_select(~torch.isnan(y0_flat))\n",
    "    ys = (ys - y0_not_nan.mean()) / y0_not_nan.std()\n",
    "\n",
    "    ###################\n",
    "    # As discussed, time must be included as a channel for the discriminator.\n",
    "    ###################\n",
    "    ys = torch.cat([ts.unsqueeze(0).unsqueeze(-1).expand(dataset_size, t_size, 1),\n",
    "                    ys.transpose(0, 1)], dim=2)\n",
    "    # shape (dataset_size=1000, t_size=100, 1 + data_size=3)\n",
    "\n",
    "    ###################\n",
    "    # Package up.\n",
    "    ###################\n",
    "    data_size = ys.size(-1) - 1  # How many channels the data has (not including time, hence the minus one).\n",
    "    ys_coeffs = torchcde.linear_interpolation_coeffs(ys)  # as per neural CDEs.\n",
    "    dataset = torch.utils.data.TensorDataset(ys_coeffs)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return ts, data_size, dataloader\n",
    "\n",
    "\n",
    "###################\n",
    "# We'll plot some results at the end.\n",
    "###################\n",
    "def plot(ts, generator, dataloader, num_plot_samples, plot_locs):\n",
    "    # Get samples\n",
    "    real_samples, = next(iter(dataloader))\n",
    "    assert num_plot_samples <= real_samples.size(0)\n",
    "    real_samples = torchcde.LinearInterpolation(real_samples).evaluate(ts)\n",
    "    real_samples = real_samples[..., 1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_samples = generator(ts, real_samples.size(0)).cpu()\n",
    "    generated_samples = torchcde.LinearInterpolation(generated_samples).evaluate(ts)\n",
    "    generated_samples = generated_samples[..., 1]\n",
    "\n",
    "    # # Plot histograms\n",
    "    # for prop in plot_locs:\n",
    "    #     time = int(prop * (real_samples.size(1) - 1))\n",
    "    #     real_samples_time = real_samples[:, time]\n",
    "    #     generated_samples_time = generated_samples[:, time]\n",
    "    #     _, bins, _ = plt.hist(real_samples_time.cpu().numpy(), bins=32, alpha=0.7, label='Real', color='dodgerblue',\n",
    "    #                           density=True)\n",
    "    #     bin_width = bins[1] - bins[0]\n",
    "    #     num_bins = int((generated_samples_time.max() - generated_samples_time.min()).item() // bin_width)\n",
    "    #     plt.hist(generated_samples_time.cpu().numpy(), bins=num_bins, alpha=0.7, label='Generated', color='crimson',\n",
    "    #              density=True)\n",
    "    #     plt.legend()\n",
    "    #     plt.xlabel('Value')\n",
    "    #     plt.ylabel('Density')\n",
    "    #     plt.title(f'Marginal distribution at time {time}.')\n",
    "    #     plt.tight_layout()\n",
    "    #     plt.show()\n",
    "\n",
    "    real_samples = real_samples[:num_plot_samples]\n",
    "    generated_samples = generated_samples[:num_plot_samples]\n",
    "\n",
    "    # Plot samples\n",
    "    real_first = True\n",
    "    generated_first = True\n",
    "    for real_sample_ in real_samples:\n",
    "        kwargs = {\"label\": \"Real\"} if real_first else {}\n",
    "        plt.plot(\n",
    "            ts.detach().cpu().numpy(),\n",
    "            real_sample_.detach().cpu().numpy(),\n",
    "            color=\"dodgerblue\",\n",
    "            linewidth=0.5,\n",
    "            alpha=0.7,\n",
    "            **kwargs,\n",
    "        )\n",
    "        real_first = False\n",
    "    for generated_sample_ in generated_samples:\n",
    "        kwargs = {\"label\": \"Generated\"} if generated_first else {}\n",
    "        plt.plot(\n",
    "            ts.detach().cpu().numpy(),\n",
    "            generated_sample_.detach().cpu().numpy(),\n",
    "            color=\"crimson\",\n",
    "            linewidth=0.5,\n",
    "            alpha=0.7,\n",
    "            **kwargs,\n",
    "        )\n",
    "        generated_first = False\n",
    "    plt.legend()\n",
    "    plt.title(f\"{num_plot_samples} samples from both real and generated distributions.\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "###################\n",
    "# Now do normal GAN training, and plot the results.\n",
    "#\n",
    "# GANs are famously tricky and SDEs trained as GANs are no exception. Hopefully you can learn from our experience and\n",
    "# get these working faster than we did -- we found that several tricks were often helpful to get this working in a\n",
    "# reasonable fashion:\n",
    "# - Stochastic weight averaging (average out the oscillations in GAN training).\n",
    "# - Weight decay (reduce the oscillations in GAN training).\n",
    "# - Final tanh nonlinearities in the architectures of the vector fields, as above. (To avoid the model blowing up.)\n",
    "# - Adadelta (interestingly seems to be a lot better than either SGD or Adam).\n",
    "# - Choosing a good learning rate (always important).\n",
    "# - Scaling the weights at initialisation to be roughly the right size (chosen through empirical trial-and-error).\n",
    "###################\n",
    "\n",
    "def evaluate_loss(ts, batch_size, dataloader, generator, discriminator):\n",
    "    with torch.no_grad():\n",
    "        total_samples = 0\n",
    "        total_loss = 0\n",
    "        for real_samples, in dataloader:\n",
    "            generated_samples = generator(ts, batch_size)\n",
    "            generated_score = discriminator(generated_samples)\n",
    "            real_score = discriminator(real_samples)\n",
    "            loss = generated_score - real_score\n",
    "            total_samples += batch_size\n",
    "            total_loss += loss.item() * batch_size\n",
    "    return total_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "        # Architectural hyperparameters. These are quite small for illustrative purposes.\n",
    "        initial_noise_size=5,  # How many noise dimensions to sample at the start of the SDE.\n",
    "        noise_size=3,          # How many dimensions the Brownian motion has.\n",
    "        hidden_size=16,        # How big the hidden size of the generator SDE and the discriminator CDE are.\n",
    "        mlp_size=16,           # How big the layers in the various MLPs are.\n",
    "        num_layers=1,          # How many hidden layers to have in the various MLPs.\n",
    "\n",
    "        # Training hyperparameters. Be prepared to tune these very carefully, as with any GAN.\n",
    "        generator_lr=2e-4,      # Learning rate often needs careful tuning to the problem.\n",
    "        discriminator_lr=1e-3,  # Learning rate often needs careful tuning to the problem.\n",
    "        batch_size=1024,        # Batch size.\n",
    "        steps=10,            # How many steps to train both generator and discriminator for.\n",
    "        init_mult1=3,           # Changing the initial parameter size can help.\n",
    "        init_mult2=0.5,         #\n",
    "        weight_decay=0.01,      # Weight decay.\n",
    "        swa_step_start=5000,    # When to start using stochastic weight averaging.\n",
    "\n",
    "        # Evaluation and plotting hyperparameters\n",
    "        steps_per_print=10,                   # How often to print the loss.\n",
    "        num_plot_samples=50,                  # How many samples to use on the plots at the end.\n",
    "        plot_locs=(0.1, 0.3, 0.5, 0.7, 0.9),  # Plot some marginal distributions at this proportion of the way along.\n",
    "):\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    device = 'cuda' if is_cuda else 'cpu'\n",
    "    if not is_cuda:\n",
    "        print(\"Warning: CUDA not available; falling back to CPU but this is likely to be very slow.\")\n",
    "\n",
    "    # Data\n",
    "    ts, data_size, train_dataloader = get_data(batch_size=batch_size, device=device)\n",
    "    infinite_train_dataloader = (elem for it in iter(lambda: train_dataloader, None) for elem in it)\n",
    "\n",
    "    # Models\n",
    "    generator = Generator(data_size, initial_noise_size, noise_size, hidden_size, mlp_size, num_layers).to(device)\n",
    "    discriminator = Discriminator(data_size, hidden_size, mlp_size, num_layers).to(device)\n",
    "    # Weight averaging really helps with GAN training.\n",
    "    averaged_generator = swa_utils.AveragedModel(generator)\n",
    "    averaged_discriminator = swa_utils.AveragedModel(discriminator)\n",
    "\n",
    "    # Picking a good initialisation is important!\n",
    "    # In this case these were picked by making the parameters for the t=0 part of the generator be roughly the right\n",
    "    # size that the untrained t=0 distribution has a similar variance to the t=0 data distribution.\n",
    "    # Then the func parameters were adjusted so that the t>0 distribution looked like it had about the right variance.\n",
    "    # What we're doing here is very crude -- one can definitely imagine smarter ways of doing things.\n",
    "    # (e.g. pretraining the t=0 distribution)\n",
    "    with torch.no_grad():\n",
    "        for param in generator._initial.parameters():\n",
    "            param *= init_mult1\n",
    "        for param in generator._func.parameters():\n",
    "            param *= init_mult2\n",
    "\n",
    "    # Optimisers. Adadelta turns out to be a much better choice than SGD or Adam, interestingly.\n",
    "    generator_optimiser = torch.optim.Adadelta(generator.parameters(), lr=generator_lr, weight_decay=weight_decay)\n",
    "    discriminator_optimiser = torch.optim.Adadelta(discriminator.parameters(), lr=discriminator_lr,\n",
    "                                                   weight_decay=weight_decay)\n",
    "\n",
    "    # Train both generator and discriminator.\n",
    "    trange = tqdm.tqdm(range(steps))\n",
    "    for step in trange:\n",
    "        real_samples, = next(infinite_train_dataloader)\n",
    "\n",
    "        generated_samples = generator(ts, batch_size)\n",
    "        generated_score = discriminator(generated_samples)\n",
    "        real_score = discriminator(real_samples)\n",
    "        loss = generated_score - real_score\n",
    "        loss.backward()\n",
    "\n",
    "        for param in generator.parameters():\n",
    "            param.grad *= -1\n",
    "        generator_optimiser.step()\n",
    "        discriminator_optimiser.step()\n",
    "        generator_optimiser.zero_grad()\n",
    "        discriminator_optimiser.zero_grad()\n",
    "\n",
    "        ###################\n",
    "        # We constrain the Lipschitz constant of the discriminator using carefully-chosen clipping (and the use of\n",
    "        # LipSwish activation functions).\n",
    "        ###################\n",
    "        with torch.no_grad():\n",
    "            for module in discriminator.modules():\n",
    "                if isinstance(module, torch.nn.Linear):\n",
    "                    lim = 1 / module.out_features\n",
    "                    module.weight.clamp_(-lim, lim)\n",
    "\n",
    "        # Stochastic weight averaging typically improves performance.\n",
    "        if step > swa_step_start:\n",
    "            averaged_generator.update_parameters(generator)\n",
    "            averaged_discriminator.update_parameters(discriminator)\n",
    "\n",
    "        if (step % steps_per_print) == 0 or step == steps - 1:\n",
    "            total_unaveraged_loss = evaluate_loss(ts, batch_size, train_dataloader, generator, discriminator)\n",
    "            if step > swa_step_start:\n",
    "                total_averaged_loss = evaluate_loss(ts, batch_size, train_dataloader, averaged_generator.module,\n",
    "                                                    averaged_discriminator.module)\n",
    "                trange.write(f\"Step: {step:3} Loss (unaveraged): {total_unaveraged_loss:.4f} \"\n",
    "                             f\"Loss (averaged): {total_averaged_loss:.4f}\")\n",
    "            else:\n",
    "                trange.write(f\"Step: {step:3} Loss (unaveraged): {total_unaveraged_loss:.4f}\")\n",
    "    generator.load_state_dict(averaged_generator.module.state_dict())\n",
    "    discriminator.load_state_dict(averaged_discriminator.module.state_dict())\n",
    "\n",
    "    time, dimension_of_SDE, test_dataloader = get_data(batch_size=batch_size, device=device)\n",
    "\n",
    "    plot(ts, generator, test_dataloader, num_plot_samples, plot_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CUDA not available; falling back to CPU but this is likely to be very slow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1024x17 and 2x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfire\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/fire/core.py:143\u001b[0m, in \u001b[0;36mFire\u001b[0;34m(component, command, name, serialize)\u001b[0m\n\u001b[1;32m    140\u001b[0m   context\u001b[38;5;241m.\u001b[39mupdate(caller_globals)\n\u001b[1;32m    141\u001b[0m   context\u001b[38;5;241m.\u001b[39mupdate(caller_locals)\n\u001b[0;32m--> 143\u001b[0m component_trace \u001b[38;5;241m=\u001b[39m \u001b[43m_Fire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsed_flag_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m component_trace\u001b[38;5;241m.\u001b[39mHasError():\n\u001b[1;32m    146\u001b[0m   _DisplayError(component_trace)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/fire/core.py:477\u001b[0m, in \u001b[0;36m_Fire\u001b[0;34m(component, args, parsed_flag_args, context, name)\u001b[0m\n\u001b[1;32m    474\u001b[0m is_class \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39misclass(component)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m   component, remaining_args \u001b[38;5;241m=\u001b[39m \u001b[43m_CallAndUpdateTrace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m      \u001b[49m\u001b[43mremaining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcomponent_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtreatment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroutine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m   handled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FireError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/fire/core.py:693\u001b[0m, in \u001b[0;36m_CallAndUpdateTrace\u001b[0;34m(component, args, component_trace, treatment, target)\u001b[0m\n\u001b[1;32m    691\u001b[0m   component \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mrun_until_complete(fn(\u001b[38;5;241m*\u001b[39mvarargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 693\u001b[0m   component \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvarargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m treatment \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    696\u001b[0m   action \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mINSTANTIATED_CLASS\n",
      "Cell \u001b[0;32mIn[38], line 62\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(initial_noise_size, noise_size, hidden_size, mlp_size, num_layers, generator_lr, discriminator_lr, batch_size, steps, init_mult1, init_mult2, weight_decay, swa_step_start, steps_per_print, num_plot_samples, plot_locs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m trange:\n\u001b[1;32m     60\u001b[0m     real_samples, \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(infinite_train_dataloader)\n\u001b[0;32m---> 62\u001b[0m     generated_samples \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     generated_score \u001b[38;5;241m=\u001b[39m discriminator(generated_samples)\n\u001b[1;32m     64\u001b[0m     real_score \u001b[38;5;241m=\u001b[39m discriminator(real_samples)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 22\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, ts, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial(init_noise)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# We use the reversible Heun method to get accurate gradients whilst using the adjoint method.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m xs \u001b[38;5;241m=\u001b[39m \u001b[43mtorchsde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msdeint_adjoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreversible_heun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                             \u001b[49m\u001b[43madjoint_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madjoint_reversible_heun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m ys \u001b[38;5;241m=\u001b[39m xs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Normalise the data to the form that the discriminator expects, in particular including time as a channel.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torchsde/_core/adjoint.py:233\u001b[0m, in \u001b[0;36msdeint_adjoint\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adjoint_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sde, nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`sde` must be an instance of nn.Module to specify the adjoint parameters; alternatively they \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    230\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan be specified explicitly via the `adjoint_params` argument. If there are no parameters \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    231\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthen it is allowable to set `adjoint_params=()`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 233\u001b[0m sde, y0, ts, bm, method, options \u001b[38;5;241m=\u001b[39m \u001b[43msdeint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_contract\u001b[49m\u001b[43m(\u001b[49m\u001b[43msde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madaptive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogqp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m misc\u001b[38;5;241m.\u001b[39massert_no_grad([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrtol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madjoint_rtol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124matol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madjoint_atol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt_min\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    235\u001b[0m                     [ts, dt, rtol, adjoint_rtol, atol, adjoint_atol, dt_min])\n\u001b[1;32m    236\u001b[0m adjoint_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(sde\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;28;01mif\u001b[39;00m adjoint_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(adjoint_params)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torchsde/_core/sdeint.py:212\u001b[0m, in \u001b[0;36mcheck_contract\u001b[0;34m(sde, y0, ts, bm, method, adaptive, options, names, logqp)\u001b[0m\n\u001b[1;32m    210\u001b[0m has_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    211\u001b[0m has_g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m _f, _g \u001b[38;5;241m=\u001b[39m \u001b[43msde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_and_g\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m f_drift_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_f\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m    214\u001b[0m g_diffusion_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_g\u001b[38;5;241m.\u001b[39msize())\n",
      "Cell \u001b[0;32mIn[35], line 55\u001b[0m, in \u001b[0;36mOUGeneratorFunc.f_and_g\u001b[0;34m(self, t, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m drift \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mu \u001b[38;5;241m*\u001b[39m t_expanded \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_theta \u001b[38;5;241m*\u001b[39m x \n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Diffusion components\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vol_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linear(diffusion) \n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m drift, diffusion\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_noise_size)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 25\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/container.py:249\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 249\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/module.py:1727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1730\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neuralSDE/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1024x17 and 2x16)"
     ]
    }
   ],
   "source": [
    "fire.Fire(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralSDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
